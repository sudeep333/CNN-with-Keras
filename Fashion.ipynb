{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('./fashionmnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Training Data\n",
    "\n",
    "data_train = pd.read_csv('./fashionmnist/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('./fashionmnist/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into features and labels\n",
    "#Converting X into numpy array\n",
    "#Converting y into 1-hot encoding by using to_categorical from keras\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Training Data\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(data_train.iloc[:, 0])\n",
    "\n",
    "#Testing Data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(data_test.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b752f54a8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b752c6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test drawing an image, just to check\n",
    "\n",
    "test_image = X[0].reshape(28,28)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000, 10)\n",
      "(12000, 784) (48000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of all splits\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train, test and validation splits in numpy\n",
    "# And their outputs in categorical or 1-hot encoding\n",
    "# it's time to reshape the data into image format i.e. 28 x 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_size, img_size, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) (48000, 10)\n",
      "(12000, 28, 28, 1) (48000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of all splits\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting input data into float value\n",
    "# Dividing all the values by 255 because ML works best when data in scaled into 0 and 1\n",
    "# Note - Pixel maximum value can't go beyond 255.\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b74c086a0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAD35JREFUeJzt3XuMHeV5x/Hfsxfv2rs4eG2v7RoTE+JEcV3ipFu7qauW1oU6NK2JVFCIhNwqzaYStE0VVaH8A/9UsqqGNH+0kZzGwqmAJCohdiQrCXWrUqqIsFASiJ0E4i6wXuMrsb0Y7/XpHzuOFrPzzvG5zbGe70ey9px55/Ls+Px2zjnvzLzm7gIQT1vZBQAoB+EHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBURzM3tsC6vFs9zdwkEMoFvaEJH7dK5q0p/Ga2TdIXJLVL+hd335mav1s92mxba9kkgISn/EDF81b9tt/M2iX9k6QPS1ov6Q4zW1/t+gA0Vy2f+TdJesndD7v7hKSvStpen7IANFot4V8t6dU5z0eyaW9hZoNmNmRmQ5Mar2FzAOqplvDP96XC264Pdvdd7j7g7gOd6qphcwDqqZbwj0haM+f5NZJGaysHQLPUEv6nJa0zs+vMbIGkj0naV5+yADRa1V197j5lZndL+o5mu/p2u/uP6lYZgIaqqZ/f3fdL2l+nWgA0Eaf3AkERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRNo/Sa2bCkc5KmJU25+0A9igLQeDWFP/M77n6yDusB0ES87QeCqjX8Lum7ZvaMmQ3WoyAAzVHr2/4t7j5qZv2SHjezH7v7E3NnyP4oDEpStxbVuDkA9VLTkd/dR7OfxyU9JmnTPPPscvcBdx/oVFctmwNQR1WH38x6zOyqi48l3SzphXoVBqCxannbv0LSY2Z2cT0Pu/u361IVgIarOvzufljS++tYC4AmoqsPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUPUbpRa1mxz7I596cOhrgxQd/Nb/xbPrlt+4vn6pp29aRv36fnk4vXLDPU+uWJJ+aSq8/oX1pX7J9+tTpqtc9F0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqsJ/fzHZL+oik4+6+IZvWJ+lrktZKGpZ0u7u/3rgyr2yN7BOuVduiRen2lf3J9hf/bFWy/YEt/5rb9tcHPp5ctlaN3K+1rvvUJz+U2/a3f/NQctld73lXTdu+qJIj/4OStl0y7R5JB9x9naQD2XMAV5DC8Lv7E5IuPaVou6Q92eM9km6tc10AGqzaz/wr3P2oJGU/0+8NAbSchp/bb2aDkgYlqVvpz5cAmqfaI/8xM1slSdnP43kzuvsudx9w94FOdVW5OQD1Vm3490nakT3eIWlvfcoB0CyF4TezRyR9T9J7zWzEzD4haaekm8zsRUk3Zc8BXEHMm3it+GLr8822tWnbuyxF19SnlHy9fceaa3Lbxq9Pfxf7yrb0R7HOM+n9smjLyWT7qZeX5LYtHUofe8ZuGUu2X3ffeLJ9+uBPk+21sF/7lWT78B/2Jts7NpzNbXvPstxP0ZKkC380kdv2vbN7dWbqREUvZs7wA4Ii/EBQhB8IivADQRF+ICjCDwTV/Ft3J7rUrKMzvWhnfrkz589XXZKk0rvrUg4/vDHZ3nkw/7TpD95yMLnsyL+/L9k+1ZveL2fGupPtC1fmd9fZH+d3WUnSZ6//r2T77377cLL9387ekNv26Eh6n65YdC7Zfm3PoWR7/0T6VPbejvzf/Zqu9NXx/9OX+D87355cdi6O/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVPP7+RP96T6Z7vctaq9FW3e6v9oWLsxvW/KO5LJH/uCXku2dv5++LLbj++k+4+nu/H069Pj69LZv+Hmy/Za16fME/mLpk8n2m7//57ltJ46m99v69UeS7TuP/V6y/eR4T27b+5eOJpcdn05H4+R4+pLdxZ0Xku1tyv8/a7eZ5LIv35b/epp4MH2uzFtrABAS4QeCIvxAUIQfCIrwA0ERfiAowg8E1fx+/oT2X35vsv3w7Utz2yb6ptPrXpq+zfNVvW8m26dn8v9OLupKn3+wYOZEsv3nP1iW3vbV6X7fzZt/ktu2tS993fnRyauT7b3t6f7qfz71G8n229b9b27bpp6fJZf98Xh6+O8VC/Jvfy1J716Yfwvsw28uTy577cJLx6Z9q7Hp9C3P3yhoHzmfv9+H3+hLr/vdk7ltM12V35eCIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFXYz29muyV9RNJxd9+QTbtf0iclXezAvtfd9xeta7K/R699PL9f+E8H06sYvpDfH/6D06uTy3a0pfvK35ys/DroSy3uSveFH3opXduyG04l2z+08v/S2+/I3/7B8+l7CRQZHU+fB1Ckr/ON3Lb/OJO+10D/gvS984uue78wk/9/urxg3ZOevv/96Yn8ewVI0usT+fd/kKTujvy++v6udG2rbsg/v2HvwvRrca5KjvwPSto2z/TPu/vG7F9h8AG0lsLwu/sTktKnOwG44tTymf9uM/uhme02syV1qwhAU1Qb/i9Kul7SRklHJX0ub0YzGzSzITMbmn4z//MfgOaqKvzufszdp919RtKXJG1KzLvL3QfcfaB9YfpLEgDNU1X4zWzu5VYflfRCfcoB0CyVdPU9IulGScvMbETSfZJuNLONklzSsKRPNbBGAA1g3sRx6Rdbn2+2rfnFDGxILj/624tz28auTff59r7zTLJ9eW/6+4i1vfkdHgvb8/tsJWlxR/peAf0F16UX9Tl321TVyy5qS9/n4IKnz3/otPR9FO66+tXctp9NjhVsO1176t73RXoKzvs4N1O0z9O/97fG0q/l1H5b2ZF+rR5InB/x6J37deLgKUuuIMMZfkBQhB8IivADQRF+ICjCDwRF+IGgmnrrbuvsUMfylbntU8+mbzO9aijdvVIL61yQbH9taf7lC/6Oq5LLTvan270j3TNjU+kuLZtKd1ultBUs6xV1GuX71mT++mcWpbsRpxamu9sKruiVErXbTHqfTi9IHxenuwuOmwX7reN8fvHt4+nX+YLh/CHdJ0YrjzRHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqqn9/D41remT+ZfGdqxakV5+ceJOQAX9tjaeHkbbz6UvL50+mX97bX/tWHLZtvwRtEvX6Au6U+svOoWg+pup1y59hkG5ZnoSOZiq/FwYjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRT+/nlLp/M72+fOjKaXv5IDdtuK7g2vDO9K9qW9iWWTfdI+2T61t5mNV40X4syt12kvaC3vei282X+brXUVvBa1ETi9TRe+RkKHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjCfn4zWyPpK5JWSpqRtMvdv2BmfZK+JmmtpGFJt7v7640rtUYz6eucveBe6dPHjtezGqAh3NPnlMxVyZF/StJn3P19kn5d0l1mtl7SPZIOuPs6SQey5wCuEIXhd/ej7v5s9vicpEOSVkvaLmlPNtseSbc2qkgA9XdZn/nNbK2kD0h6StIKdz8qzf6BkNRf7+IANE7F4TezXkmPSvq0u5+9jOUGzWzIzIYmNV5NjQAaoKLwm1mnZoP/kLt/I5t8zMxWZe2rJM37jZi773L3AXcf6FRXPWoGUAeF4bfZS86+LOmQuz8wp2mfpB3Z4x2S9ta/PACNUsklvVsk3SnpeTN7Lpt2r6Sdkr5uZp+Q9Iqk2xpTIoBGKAy/uz+p/Fusb61vOQCahTP8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0EVht/M1pjZf5rZITP7kZn9VTb9fjM7YmbPZf9uaXy5AOqlo4J5piR9xt2fNbOrJD1jZo9nbZ93939oXHkAGqUw/O5+VNLR7PE5MzskaXWjCwPQWJf1md/M1kr6gKSnskl3m9kPzWy3mS3JWWbQzIbMbGhS4zUVC6B+Kg6/mfVKelTSp939rKQvSrpe0kbNvjP43HzLufsudx9w94FOddWhZAD1UFH4zaxTs8F/yN2/IUnufszdp919RtKXJG1qXJkA6q2Sb/tN0pclHXL3B+ZMXzVnto9KeqH+5QFolEq+7d8i6U5Jz5vZc9m0eyXdYWYbJbmkYUmfakiFABqikm/7n5Rk8zTtr385AJqFM/yAoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBmbs3b2NmJyS9PGfSMkknm1bA5WnV2lq1LonaqlXP2t7p7ssrmbGp4X/bxs2G3H2gtAISWrW2Vq1LorZqlVUbb/uBoAg/EFTZ4d9V8vZTWrW2Vq1LorZqlVJbqZ/5AZSn7CM/gJKUEn4z22ZmPzGzl8zsnjJqyGNmw2b2fDby8FDJtew2s+Nm9sKcaX1m9riZvZj9nHeYtJJqa4mRmxMjS5e671ptxOumv+03s3ZJP5V0k6QRSU9LusPdDza1kBxmNixpwN1L7xM2s9+SNCbpK+6+IZv295JOu/vO7A/nEnf/bIvUdr+ksbJHbs4GlFk1d2RpSbdK+hOVuO8Sdd2uEvZbGUf+TZJecvfD7j4h6auStpdQR8tz9ycknb5k8nZJe7LHezT74mm6nNpagrsfdfdns8fnJF0cWbrUfZeoqxRlhH+1pFfnPB9Raw357ZK+a2bPmNlg2cXMY0U2bPrF4dP7S67nUoUjNzfTJSNLt8y+q2bE63orI/zzjf7TSl0OW9z9g5I+LOmu7O0tKlPRyM3NMs/I0i2h2hGv662M8I9IWjPn+TWSRkuoY17uPpr9PC7pMbXe6MPHLg6Smv08XnI9v9BKIzfPN7K0WmDftdKI12WE/2lJ68zsOjNbIOljkvaVUMfbmFlP9kWMzKxH0s1qvdGH90nakT3eIWlvibW8RauM3Jw3srRK3netNuJ1KSf5ZF0Z/yipXdJud/+7phcxDzN7l2aP9tLsIKYPl1mbmT0i6UbNXvV1TNJ9kr4p6euSrpX0iqTb3L3pX7zl1HajZt+6/mLk5oufsZtc229K+m9Jz0uaySbfq9nP16Xtu0Rdd6iE/cYZfkBQnOEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wfDQWNzXW3yxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b74d319e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test drawing an image, just to check everything looks good\n",
    "\n",
    "test_image2 = X_train[0].reshape(28,28)\n",
    "plt.imshow(test_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to prepare Keras Model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "# Image Dimension\n",
    "img_size = 28\n",
    "\n",
    "# Input shape. A 4-D tensor\n",
    "input_shape = (img_size, img_size, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='random_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer= keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 168,874\n",
      "Trainable params: 168,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      " 9728/48000 [=====>........................] - ETA: 15:10 - loss: 2.3810 - acc: 0.0946"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-cc02ac659283>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     verbose=1, validation_data=(X_val, y_val))\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sudeep\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\sudeep\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sudeep\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sudeep\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sudeep\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now we will fit our data into the model that we have created.\n",
    "# NOTE: model.fit() returns a history object which can be used for further analysis.\n",
    "# Like plotting graphs of loss, accuracies etc.\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
